import os
import json
import re
import sys
import io
import contextlib
import warnings
import requests
from typing import Optional, List, Any, Tuple
from PIL import Image
import streamlit as st
import pandas as pd
import base64
from io import BytesIO
from e2b_code_interpreter import Sandbox
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv('local.env')

warnings.filterwarnings("ignore", category=UserWarning, module="pydantic")

pattern = re.compile(r"```python\n(.*?)\n```", re.DOTALL)

def code_interpret(e2b_code_interpreter: Sandbox, code: str) -> Optional[List[Any]]:
    with st.spinner('Executing code in E2B sandbox...'):
        stdout_capture = io.StringIO()
        stderr_capture = io.StringIO()

        with contextlib.redirect_stdout(stdout_capture), contextlib.redirect_stderr(stderr_capture):
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                exec = e2b_code_interpreter.run_code(code)

        if stderr_capture.getvalue():
            print("[Code Interpreter Warnings/Errors]", file=sys.stderr)
            print(stderr_capture.getvalue(), file=sys.stderr)

        if stdout_capture.getvalue():
            print("[Code Interpreter Output]", file=sys.stdout)
            print(stdout_capture.getvalue(), file=sys.stdout)

        if exec.error:
            print(f"[Code Interpreter ERROR] {exec.error}", file=sys.stderr)
            return None
        return exec.results

def match_code_blocks(llm_response: str) -> str:
    match = pattern.search(llm_response)
    if match:
        code = match.group(1)
        return code
    return ""

def chat_with_llm_code_only(e2b_code_interpreter: Sandbox, user_message: str, dataset_path: str) -> Tuple[Optional[str], str]:
    """
    ç¬¬ä¸€æ­¥ï¼šåªè®©LLMç”ŸæˆPythonä»£ç ï¼Œä¸è¦è§£é‡Šã€‚
    @param e2b_code_interpreter {Sandbox} E2Bæ²™ç›’å®ä¾‹
    @param user_message {str} ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    @param dataset_path {str} æ•°æ®é›†åœ¨æ²™ç›’ä¸­çš„è·¯å¾„
    @returns {Tuple} (ä»£ç å­—ç¬¦ä¸², LLMåŸå§‹å›å¤)
    """
    system_prompt = f"""ä½ æ˜¯ä¸€åPythonæ•°æ®ç§‘å­¦å®¶ã€‚ä½ æ‹¿åˆ°æ•°æ®é›†è·¯å¾„'{dataset_path}'å’Œç”¨æˆ·é—®é¢˜åï¼Œåªéœ€è¾“å‡ºä¸€æ®µPythonä»£ç ï¼ˆmarkdownä»£ç å—ï¼‰ï¼Œç”¨äºåˆ†ææˆ–å¯è§†åŒ–æ•°æ®ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚ä»£ç è¯»å–æ•°æ®æ—¶å¿…é¡»ä½¿ç”¨'{dataset_path}'å˜é‡ã€‚"""
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_message},
    ]
    with st.spinner('æ­£åœ¨ä»SiliconFlowå¤§æ¨¡å‹è·å–åˆ†æä»£ç ...'):
        url = "https://api.siliconflow.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {st.session_state.siliconflow_api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": st.session_state.model_name,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 2048,
            "top_p": 0.9,
            "frequency_penalty": 0.5
        }
        try:
            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()
            response_data = response.json()
            if "choices" in response_data and len(response_data["choices"]) > 0:
                response_message = response_data["choices"][0]["message"]["content"]
                python_code = match_code_blocks(response_message)
                if python_code:
                    return python_code, response_message
                else:
                    st.warning(f"æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­åŒ¹é…åˆ°Pythonä»£ç ")
                    return None, response_message
            else:
                st.error("APIå“åº”æ ¼å¼é”™è¯¯")
                return None, "APIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è·å–æ¨¡å‹å›ç­”"
        except requests.exceptions.RequestException as e:
            st.error(f"APIè¯·æ±‚é”™è¯¯: {str(e)}")
            return None, f"APIè¯·æ±‚é”™è¯¯: {str(e)}"

def chat_with_llm_explain(user_message: str, exec_result: str) -> str:
    system_prompt = "ä½ æ˜¯ä¸€åæ•°æ®åˆ†æä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œä¸‹æ–¹çš„ä»£ç æ‰§è¡Œç»“æœï¼Œç”¨ç®€æ˜ä¸­æ–‡ä¸ºç”¨æˆ·è¯¦ç»†è§£é‡Šç»“æœã€‚"
    user_prompt = f"ç”¨æˆ·é—®é¢˜ï¼š{user_message}\nä»£ç æ‰§è¡Œç»“æœï¼š{exec_result}"
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
    with st.spinner('æ­£åœ¨è®©å¤§æ¨¡å‹ä¸ºä½ è§£é‡Šåˆ†æç»“æœ...'):
        url = "https://api.siliconflow.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {st.session_state.siliconflow_api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": st.session_state.model_name,
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 1024,
            "top_p": 0.9,
            "frequency_penalty": 0.5
        }
        try:
            response = requests.post(url, json=payload, headers=headers)
            response.raise_for_status()
            response_data = response.json()
            if "choices" in response_data and len(response_data["choices"]) > 0:
                return response_data["choices"][0]["message"]["content"]
            else:
                st.error("APIå“åº”æ ¼å¼é”™è¯¯")
                return "APIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è·å–æ¨¡å‹è§£é‡Š"
        except requests.exceptions.RequestException as e:
            st.error(f"APIè¯·æ±‚é”™è¯¯: {str(e)}")
            return f"APIè¯·æ±‚é”™è¯¯: {str(e)}"

def upload_dataset(code_interpreter: Sandbox, uploaded_file) -> str:
    dataset_path = f"./{uploaded_file.name}"
    
    try:
        code_interpreter.files.write(dataset_path, uploaded_file)
        return dataset_path
    except Exception as error:
        st.error(f"Error during file upload: {error}")
        raise error


def main():
    """Main Streamlit application."""
    st.title("ğŸ“Š AI æ•°æ®å¯è§†åŒ–åŠ©æ‰‹")
    st.write("ä¸Šä¼ æ‚¨çš„æ•°æ®é›†å¹¶æå‡ºé—®é¢˜ï¼")

    # ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    default_siliconflow_api_key = os.getenv("SILICONFLOW_API_KEY", "")
    default_e2b_api_key = os.getenv("E2B_API_KEY", "")

    # Initialize session state variables
    if 'siliconflow_api_key' not in st.session_state:
        st.session_state.siliconflow_api_key = default_siliconflow_api_key
    if 'e2b_api_key' not in st.session_state:
        st.session_state.e2b_api_key = default_e2b_api_key
    if 'model_name' not in st.session_state:
        st.session_state.model_name = ''

    with st.sidebar:
        st.header("APIå¯†é’¥å’Œæ¨¡å‹é…ç½®")
        st.session_state.siliconflow_api_key = st.sidebar.text_input("SiliconFlow APIå¯†é’¥", 
                                                                   value=st.session_state.siliconflow_api_key,
                                                                   type="password")
        st.sidebar.info("ğŸ’¡ SiliconFlow - ä¸­å›½é¢†å…ˆçš„AIäº‘å¹³å°")
        st.sidebar.markdown("[è·å–SiliconFlow APIå¯†é’¥](https://cloud.siliconflow.cn/account/ak)")
        
        st.session_state.e2b_api_key = st.sidebar.text_input("E2B APIå¯†é’¥", 
                                                           value=st.session_state.e2b_api_key,
                                                           type="password")
        st.sidebar.markdown("[è·å–E2B APIå¯†é’¥](https://e2b.dev/docs/legacy/getting-started/api-key)")
        
        # æ·»åŠ SiliconFlowæ¨¡å‹é€‰é¡¹
        model_options = {
            "Qwen/Qwen2.5-7B-Instruct (é»˜è®¤ï¼Œ32Kæ–‡æœ¬ï¼Œå…è´¹)": "Qwen/Qwen2.5-7B-Instruct",
            "THUDM/glm-4-9b-chat (å¤‡é€‰ï¼Œ128Kæ–‡æœ¬ï¼Œå…è´¹)": "THUDM/glm-4-9b-chat",
            "Qwen/Qwen2.5-14B-Instruct (å¤‡é€‰ï¼Œ32Kæ–‡æœ¬ï¼Œä»˜è´¹)": "Qwen/Qwen2.5-14B-Instruct",
            "deepseek-ai/DeepSeek-V3 (å¤‡é€‰ï¼Œ64kæ–‡æœ¬ï¼Œä»˜è´¹)": "deepseek-ai/DeepSeek-V3"
        }
        st.session_state.model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=list(model_options.keys()),
            index=0  # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹
        )
        st.session_state.model_name = model_options[st.session_state.model_name]

    uploaded_file = st.file_uploader("é€‰æ‹©CSVæ–‡ä»¶", type="csv")
    
    if uploaded_file is not None:
        # Display dataset with toggle
        df = pd.read_csv(uploaded_file)
        st.write("æ•°æ®é›†:")
        show_full = st.checkbox("æ˜¾ç¤ºå®Œæ•´æ•°æ®é›†")
        if show_full:
            st.dataframe(df)
        else:
            st.write("é¢„è§ˆ(å‰5è¡Œ):")
            st.dataframe(df.head())
        # Query input
        query = st.text_area("æ‚¨æƒ³äº†è§£æ•°æ®çš„ä»€ä¹ˆä¿¡æ¯ï¼Ÿ",
                            "èƒ½å¦æ¯”è¾ƒä¸åŒç±»åˆ«ä¹‹é—´ä¸¤äººçš„å¹³å‡æˆæœ¬ï¼Ÿ")
        
        if st.button("åˆ†æ"):
            if not st.session_state.siliconflow_api_key or not st.session_state.e2b_api_key:
                st.error("è¯·åœ¨ä¾§è¾¹æ ä¸­è¾“å…¥ä¸¤ä¸ªAPIå¯†é’¥ã€‚")
            else:
                with Sandbox(api_key=st.session_state.e2b_api_key) as code_interpreter:
                    dataset_path = upload_dataset(code_interpreter, uploaded_file)
                    # ç¬¬ä¸€æ­¥ï¼šåªç”Ÿæˆä»£ç 
                    python_code, llm_code_response = chat_with_llm_code_only(code_interpreter, query, dataset_path)
                    st.write("AIç”Ÿæˆçš„åˆ†æä»£ç ï¼š")
                    st.code(python_code, language="python")
                    # ç¬¬äºŒæ­¥ï¼šæ²™ç›’æ‰§è¡Œ
                    code_results = code_interpret(code_interpreter, python_code) if python_code else None
                    # å±•ç¤ºå¯è§†åŒ–/è¡¨æ ¼ç­‰
                    if code_results:
                        for result in code_results:
                            if hasattr(result, 'png') and result.png:
                                png_data = base64.b64decode(result.png)
                                image = Image.open(BytesIO(png_data))
                                st.image(image, caption="ç”Ÿæˆçš„å¯è§†åŒ–", use_container_width=False)
                            elif hasattr(result, 'figure'):
                                fig = result.figure
                                st.pyplot(fig)
                            elif hasattr(result, 'show'):
                                st.plotly_chart(result)
                            elif isinstance(result, (pd.DataFrame, pd.Series)):
                                st.dataframe(result)
                            elif isinstance(result, list) and all(isinstance(x, str) for x in result):
                                st.info(f"è¯¥æ•°æ®é›†åŒ…å«ä»¥ä¸‹å­—æ®µï¼š{', '.join(result)}")
                            elif isinstance(result, str) and result.startswith("[") and result.endswith("]"):
                                try:
                                    import ast
                                    fields = ast.literal_eval(result)
                                    if isinstance(fields, list) and all(isinstance(x, str) for x in fields):
                                        st.info(f"è¯¥æ•°æ®é›†åŒ…å«ä»¥ä¸‹å­—æ®µï¼š{', '.join(fields)}")
                                    else:
                                        st.write(result)
                                except Exception:
                                    st.write(result)
                            else:
                                st.write(result)
                        # å–ç¬¬ä¸€ä¸ªç»“æœæ–‡æœ¬ç”¨äºè§£é‡Š
                        explain_input = code_results[0] if len(code_results) == 1 else str(code_results)
                        st.write("AIç»“æœè§£é‡Šï¼š")
                        st.write(chat_with_llm_explain(query, explain_input))
                    else:
                        st.warning("ä»£ç æ‰§è¡Œæœªè¿”å›ç»“æœï¼Œæ— æ³•ç”Ÿæˆè§£é‡Šã€‚")

if __name__ == "__main__":
    main()
